{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Project Description\n",
        "\n",
        "#### Project Overview:\n",
        "You have been hired as a Data Engineer by a research organization, tasked with developing an automated Python solution to extract, transform, and load (ETL) data on the **top 10 largest banks in the world** based on market capitalization. The data needs to be transformed to include market capitalization in various currencies (GBP, EUR, INR) using exchange rate information provided in a separate CSV file. This system will be used to generate reports for the organization on a quarterly basis.\n",
        "\n",
        "The final output will include:\n",
        "- A **CSV file** containing the market capitalization of the top 10 banks in USD, GBP, EUR, and INR.\n",
        "- A **database** storing the same information for easier querying and analysis.\n",
        "\n",
        "The process must be fully automated so that the same script can be run every financial quarter to ensure up-to-date information is compiled.\n",
        "\n",
        "### Project Details:\n",
        "\n",
        "- **Code Name**: `banks_project.py`\n",
        "- **Data Source URL**: [Top 10 Largest Banks by Market Capitalization](https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks)\n",
        "- **Exchange Rate CSV Path**: [Exchange Rate Data](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv)\n",
        "- **Initial Table Attributes (Upon Extraction)**: `Name`, `MC_USD_Billion`\n",
        "- **Final Table Attributes (After Transformation)**: `Name`, `MC_USD_Billion`, `MC_GBP_Billion`, `MC_EUR_Billion`, `MC_INR_Billion`\n",
        "- **Output CSV File Path**: `./Largest_banks_data.csv`\n",
        "- **Database Name**: `Banks.db`\n",
        "- **Database Table Name**: `Largest_banks`\n",
        "- **Log File Name**: `code_log.txt`\n",
        "\n",
        "### Project Tasks:\n",
        "\n",
        "#### **Task 1: Log Progress**  \n",
        "- **Objective**: Write a function `log_progress()` to track and log the progress of the script at different stages.\n",
        "- **Details**: Use logging to create entries in `code_log.txt` at key points in the process, such as after extraction, transformation, loading to CSV, and loading to the database.\n",
        "\n",
        "#### **Task 2: Data Extraction**  \n",
        "- **Objective**: Extract the list of the top 10 largest banks by market capitalization from the provided URL.\n",
        "- **Details**:\n",
        "  1. Inspect the webpage to identify the position and structure of the table containing the required data.\n",
        "  2. Write a function `extract()` to scrape the data and load it into a DataFrame.\n",
        "  3. Execute the extraction and verify that the DataFrame correctly contains the list of banks with their market capitalization in USD.\n",
        "\n",
        "#### **Task 3: Data Transformation**  \n",
        "- **Objective**: Transform the extracted data by converting market capitalization from USD to GBP, EUR, and INR using the exchange rate data provided in the CSV file.\n",
        "- **Details**:\n",
        "  1. Write a function `transform()` that adds new columns for the market capitalization in GBP, EUR, and INR based on the provided exchange rates.\n",
        "  2. Ensure that all values are rounded to two decimal places.\n",
        "  3. Verify that the transformation correctly computes the market capitalization in all four currencies.\n",
        "\n",
        "#### **Task 4: Load Data to CSV**  \n",
        "- **Objective**: Save the transformed DataFrame to a CSV file.\n",
        "- **Details**:\n",
        "  - Write a function `load_to_csv()` to write the transformed data to `Largest_banks_data.csv`.\n",
        "  - Verify that the output CSV file contains the correct data.\n",
        "\n",
        "#### **Task 5: Load Data to SQL Database**  \n",
        "- **Objective**: Load the transformed data into an SQLite database.\n",
        "- **Details**:\n",
        "  1. Write a function `load_to_db()` that creates a table in the database and inserts the transformed data.\n",
        "  2. Ensure the table is created if it does not already exist and that the data is correctly inserted.\n",
        "  3. Verify that the data is loaded into the `Largest_banks` table in the `Banks.db` database.\n",
        "\n",
        "#### **Task 6: Query the Database**  \n",
        "- **Objective**: Run SQL queries on the database to retrieve and verify the data.\n",
        "- **Details**:\n",
        "  1. Write a function `run_query()` to execute a SQL query that retrieves banks with market capitalization greater than 100 billion USD.\n",
        "  2. Display the results of the query and ensure they are correct.\n",
        "\n",
        "#### **Task 7: Verify Log Entries**  \n",
        "- **Objective**: Verify that the `code_log.txt` file contains log entries for all the key stages.\n",
        "- **Details**: After completing all tasks, check the log file to ensure that the process is fully logged, including the start and end of the ETL process, and the completion of each task.\n",
        "\n",
        "### Expected Outcomes:\n",
        "1. **CSV Output**: A file `Largest_banks_data.csv` containing the list of top 10 largest banks and their market capitalization in USD, GBP, EUR, and INR.\n",
        "2. **Database Output**: An SQLite database file `Banks.db` with a table `Largest_banks` storing the same data.\n",
        "3. **SQL Query Results**: A query output showing the banks with market capitalization greater than 100 billion USD.\n",
        "4. **Log File**: A log file `code_log.txt` capturing the execution progress with timestamps at each stage.\n",
        "\n",
        "### Tools and Technologies:\n",
        "- **Python**: For implementing the ETL process.\n",
        "- **Libraries**:\n",
        "  - `requests` and `BeautifulSoup` for web scraping.\n",
        "  - `pandas` for data manipulation and storage in CSV format.\n",
        "  - `sqlite3` for interacting with the SQLite database.\n",
        "  - `logging` for tracking progress and errors during the execution.\n",
        "  \n",
        "### Conclusion:\n",
        "This project will automate the process of gathering, transforming, and storing data on the top 10 largest banks in the world by market capitalization, enabling the research organization to generate up-to-date reports every quarter. The code will fetch the latest data from the internet, apply necessary currency conversions, and store the data in both CSV and database formats for easy querying and analysis. The progress will be logged to ensure traceability and error handling during the process."
      ],
      "metadata": {
        "id": "ibL1kE8DIEzZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ6Huq1uIC7t",
        "outputId": "395985b6-c9f4-4958-811b-af761de4579c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('JPMorgan Chase', 432.92, 346.34, 402.62, 35910.71)\n",
            "('Bank of America', 231.52, 185.22, 215.31, 19204.58)\n",
            "('Industrial and Commercial Bank of China', 194.56, 155.65, 180.94, 16138.75)\n",
            "('Agricultural Bank of China', 160.68, 128.54, 149.43, 13328.41)\n",
            "('HDFC Bank', 157.91, 126.33, 146.86, 13098.63)\n",
            "('Wells Fargo', 155.87, 124.7, 144.96, 12929.42)\n",
            "('HSBC Holdings PLC', 148.9, 119.12, 138.48, 12351.26)\n",
            "('Morgan Stanley', 140.83, 112.66, 130.97, 11681.85)\n",
            "('China Construction Bank', 139.82, 111.86, 130.03, 11598.07)\n",
            "('Bank of China', 136.81, 109.45, 127.23, 11348.39)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import logging\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Setup logging configuration\n",
        "logging.basicConfig(filename='code_log.txt', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "\n",
        "def log_progress(message):\n",
        "    \"\"\"This function logs the mentioned message of a given stage of the code execution to a log file.\"\"\"\n",
        "    logging.info(message)\n",
        "\n",
        "def extract(url, table_attribs):\n",
        "    \"\"\"This function extracts the required information from the website and saves it to a DataFrame.\"\"\"\n",
        "    log_progress(\"Extracting data from URL\")\n",
        "\n",
        "    # Request the content from the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Locate the table with market capitalization information\n",
        "    table = soup.find('table', {'class': 'wikitable'})\n",
        "\n",
        "    # Extract the header and rows of the table\n",
        "    headers = [header.text.strip() for header in table.find_all('th')]\n",
        "    rows = table.find_all('tr')[1:]  # Skip the header row\n",
        "\n",
        "    data = []\n",
        "    for row in rows:\n",
        "        columns = row.find_all('td')\n",
        "        if len(columns) > 1:  # Avoid empty rows\n",
        "            name = columns[1].text.strip()\n",
        "            market_cap_usd = columns[2].text.strip().replace(',', '')\n",
        "            data.append([name, market_cap_usd])\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data, columns=table_attribs)\n",
        "\n",
        "    log_progress(\"Data extracted successfully\")\n",
        "    return df\n",
        "\n",
        "def transform(df, csv_path):\n",
        "    \"\"\"This function transforms the Market Cap values from USD to GBP, EUR, INR based on exchange rates.\"\"\"\n",
        "    log_progress(\"Transforming data to different currencies\")\n",
        "\n",
        "    # Read the exchange rate CSV file\n",
        "    exchange_rates = pd.read_csv(csv_path)\n",
        "\n",
        "    # Convert Market Cap to numeric (USD)\n",
        "    df['MC_USD_Billion'] = pd.to_numeric(df['MC_USD_Billion'], errors='coerce')\n",
        "\n",
        "    # Get exchange rates from the CSV file\n",
        "    usd_to_gbp = exchange_rates.loc[exchange_rates['Currency'] == 'GBP', 'Rate'].values[0]\n",
        "    usd_to_eur = exchange_rates.loc[exchange_rates['Currency'] == 'EUR', 'Rate'].values[0]\n",
        "    usd_to_inr = exchange_rates.loc[exchange_rates['Currency'] == 'INR', 'Rate'].values[0]\n",
        "\n",
        "    # Add the transformed columns to the DataFrame\n",
        "    df['MC_GBP_Billion'] = df['MC_USD_Billion'] * usd_to_gbp\n",
        "    df['MC_EUR_Billion'] = df['MC_USD_Billion'] * usd_to_eur\n",
        "    df['MC_INR_Billion'] = df['MC_USD_Billion'] * usd_to_inr\n",
        "\n",
        "    # Round the values to 2 decimal places\n",
        "    df = df.round({'MC_USD_Billion': 2, 'MC_GBP_Billion': 2, 'MC_EUR_Billion': 2, 'MC_INR_Billion': 2})\n",
        "\n",
        "    log_progress(\"Data transformed successfully\")\n",
        "    return df\n",
        "\n",
        "def load_to_csv(df, output_path):\n",
        "    \"\"\"This function saves the final DataFrame as a CSV file.\"\"\"\n",
        "    log_progress(\"Loading data to CSV\")\n",
        "    df.to_csv(output_path, index=False)\n",
        "    log_progress(f\"Data saved to {output_path} successfully\")\n",
        "\n",
        "def load_to_db(df, sql_connection, table_name):\n",
        "    \"\"\"This function saves the final DataFrame to a database table.\"\"\"\n",
        "    log_progress(f\"Loading data to database table {table_name}\")\n",
        "\n",
        "    # Create a table if it doesn't exist\n",
        "    cursor = sql_connection.cursor()\n",
        "    cursor.execute(f\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
        "            Name TEXT,\n",
        "            MC_USD_Billion REAL,\n",
        "            MC_GBP_Billion REAL,\n",
        "            MC_EUR_Billion REAL,\n",
        "            MC_INR_Billion REAL\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    # Insert data into the table\n",
        "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
        "    log_progress(\"Data loaded to database successfully\")\n",
        "\n",
        "def run_query(query_statement, sql_connection):\n",
        "    \"\"\"This function runs a query on the database table and prints the output.\"\"\"\n",
        "    log_progress(f\"Running query: {query_statement}\")\n",
        "    cursor = sql_connection.cursor()\n",
        "    cursor.execute(query_statement)\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    for row in result:\n",
        "        print(row)\n",
        "    log_progress(\"Query executed successfully\")\n",
        "\n",
        "# Main Program to execute the tasks\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Task 1: Log the start of the process\n",
        "    log_progress(\"ETL Process Started\")\n",
        "\n",
        "    # Task 2: Extract data from URL\n",
        "    url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
        "    table_attribs = ['Name', 'MC_USD_Billion']\n",
        "    df = extract(url, table_attribs)\n",
        "\n",
        "    # Task 3: Transform data using exchange rates from CSV\n",
        "    exchange_rate_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'\n",
        "    df_transformed = transform(df, exchange_rate_path)\n",
        "\n",
        "    # Task 4: Load transformed data to CSV\n",
        "    output_csv_path = './Largest_banks_data.csv'\n",
        "    load_to_csv(df_transformed, output_csv_path)\n",
        "\n",
        "    # Task 5: Load transformed data to the database\n",
        "    db_connection = sqlite3.connect('Banks.db')\n",
        "    table_name = 'Largest_banks'\n",
        "    load_to_db(df_transformed, db_connection, table_name)\n",
        "\n",
        "    # Task 6: Run queries on the database\n",
        "    query = \"SELECT * FROM Largest_banks WHERE MC_USD_Billion > 100\"\n",
        "    run_query(query, db_connection)\n",
        "\n",
        "    # Task 7: Verify that log entries are complete\n",
        "    log_progress(\"ETL Process Completed\")\n",
        "\n",
        "    # Close database connection\n",
        "    db_connection.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3M8wewJokeMw"
      }
    }
  ]
}